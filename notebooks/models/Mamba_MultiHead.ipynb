{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../../')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-SVX9K6RK_jk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Concatenate,Bidirectional, Attention\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "imSt6RsNLF19"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess data\n",
        "def load_data(file_path):\n",
        "    df = pd.read_csv(file_path, header=None, names=['event_type', 'agent_id', 'context'])\n",
        "    return df\n",
        "\n",
        "def preprocess_data(df):\n",
        "    le_event = LabelEncoder()\n",
        "    le_agent = LabelEncoder()\n",
        "    le_context = LabelEncoder()\n",
        "\n",
        "    # Replace empty strings with a special token\n",
        "    df['context'] = df['context'].replace('', '<EMPTY>')\n",
        "\n",
        "    df['event_type_encoded'] = le_event.fit_transform(df['event_type'])\n",
        "    df['agent_id_encoded'] = le_agent.fit_transform(df['agent_id'])\n",
        "    df['context_encoded'] = le_context.fit_transform(df['context'])\n",
        "\n",
        "    return df, le_event, le_agent, le_context\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ms5K8836LZ9F"
      },
      "outputs": [],
      "source": [
        "# Create sequences\n",
        "def create_sequences(df, sequence_length):\n",
        "    sequences = []\n",
        "    targets = []\n",
        "\n",
        "    for i in range(len(df) - sequence_length):\n",
        "        seq = df.iloc[i:i+sequence_length]\n",
        "        target = df.iloc[i+sequence_length]\n",
        "\n",
        "        sequences.append(seq[['event_type_encoded', 'agent_id_encoded', 'context_encoded']].values)\n",
        "        targets.append([target['event_type_encoded'], target['agent_id_encoded'], target['context_encoded']])\n",
        "\n",
        "    return np.array(sequences), np.array(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "o1a9OKyrLmoi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "\n",
        "class SimplifiedMambaBlock(layers.Layer):\n",
        "    def __init__(self, d_model, d_state, expand=2, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.d_model = d_model\n",
        "        self.d_state = d_state\n",
        "        self.expand = expand\n",
        "\n",
        "        self.in_proj = layers.Dense(d_model * expand * 2)\n",
        "        self.conv1d = layers.Conv1D(d_model * expand, kernel_size=4, padding='same', groups=d_model * expand)\n",
        "        self.act = layers.Activation('silu')\n",
        "        self.out_proj = layers.Dense(d_model)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.seq_len = input_shape[1]\n",
        "        self.A = self.add_weight(shape=(self.d_state, self.d_state), initializer='orthogonal', name='A')\n",
        "        self.B = self.add_weight(shape=(self.d_state, self.d_model * self.expand), initializer='glorot_uniform', name='B')\n",
        "        self.C = self.add_weight(shape=(self.d_model * self.expand, self.d_state), initializer='glorot_uniform', name='C')\n",
        "        self.D = self.add_weight(shape=(self.d_model * self.expand,), initializer='zeros', name='D')\n",
        "\n",
        "    def call(self, x):\n",
        "        skip = x\n",
        "        x = self.in_proj(x)\n",
        "        x, gate = tf.split(x, 2, axis=-1)\n",
        "        x = self.conv1d(x)\n",
        "        x = self.act(x)\n",
        "\n",
        "        # Simplified selective scan\n",
        "        u = tf.matmul(x, tf.transpose(self.B))\n",
        "        v = tf.matmul(self.C, tf.linalg.expm(self.A * (1.0 / self.seq_len)))\n",
        "        y = tf.matmul(u, v)\n",
        "        y = y + x * self.D\n",
        "\n",
        "        y = y * gate\n",
        "        y = self.out_proj(y)\n",
        "        return y + skip\n",
        "\n",
        "def build_model(input_shape, num_classes, n_layers=4):\n",
        "    input_event = Input(shape=(input_shape[0], 1))\n",
        "    input_agent = Input(shape=(input_shape[0], 1))\n",
        "    input_context = Input(shape=(input_shape[0], 1))\n",
        "\n",
        "    concat = Concatenate()([input_event, input_agent, input_context])\n",
        "\n",
        "    x = layers.Dense(64)(concat)\n",
        "\n",
        "    for _ in range(n_layers):\n",
        "        x = SimplifiedMambaBlock(d_model=64, d_state=16)(x)\n",
        "\n",
        "    x = layers.LayerNormalization()(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    output_event = Dense(num_classes[0], activation='softmax', name='event_type')(x)\n",
        "    output_agent = Dense(num_classes[1], activation='softmax', name='agent_id')(x)\n",
        "    output_context = Dense(num_classes[2], activation='softmax', name='context')(x)\n",
        "\n",
        "    model = Model(inputs=[input_event, input_agent, input_context],\n",
        "                  outputs=[output_event, output_agent, output_context])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy','accuracy','accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_next_moves(model, initial_sequence, le_event, le_agent, le_context, n_predictions):\n",
        "    predictions = []\n",
        "    current_sequence = initial_sequence.copy()\n",
        "\n",
        "    for _ in range(n_predictions):\n",
        "        custom_event = current_sequence[:, 0].reshape(1, -1, 1)\n",
        "        custom_agent = current_sequence[:, 1].reshape(1, -1, 1)\n",
        "        custom_context = current_sequence[:, 2].reshape(1, -1, 1)\n",
        "\n",
        "        prediction = model.predict([custom_event, custom_agent, custom_context])\n",
        "\n",
        "        predicted_event = le_event.inverse_transform([np.argmax(prediction[0])])[0]\n",
        "        predicted_agent = le_agent.inverse_transform([np.argmax(prediction[1])])[0]\n",
        "        predicted_context = le_context.inverse_transform([np.argmax(prediction[2])])[0]\n",
        "\n",
        "        predicted_context = '' if predicted_context == '<EMPTY>' else predicted_context\n",
        "\n",
        "        predictions.append((predicted_event, predicted_agent, predicted_context))\n",
        "\n",
        "        # Update the sequence for the next prediction\n",
        "        new_row = np.array([[\n",
        "            le_event.transform([predicted_event])[0],\n",
        "            le_agent.transform([predicted_agent])[0],\n",
        "            le_context.transform([predicted_context if predicted_context != '' else '<EMPTY>'])[0]\n",
        "        ]])\n",
        "        current_sequence = np.vstack((current_sequence[1:], new_row))\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and preprocess data\n",
        "df = load_data('../../data/processed/games/tic-tac-toe/1k_single_agent.csv')\n",
        "df, le_event, le_agent, le_context = preprocess_data(df)\n",
        "\n",
        "# Create sequences\n",
        "sequence_length = 10  # Changed to 10\n",
        "X, y = create_sequences(df, sequence_length)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\vaibh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:187: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Exception encountered when calling SimplifiedMambaBlock.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'simplified_mamba_block' (of type SimplifiedMambaBlock). Either the `SimplifiedMambaBlock.call()` method is incorrect, or you need to implement the `SimplifiedMambaBlock.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nDimensions must be equal, but are 16 and 128 for '{{node MatMul_2}} = BatchMatMulV2[T=DT_FLOAT, adj_x=false, adj_y=false, grad_x=false, grad_y=false](MatMul, MatMul_1)' with input shapes: [?,10,16], [128,16].\u001b[0m\n\nArguments received by SimplifiedMambaBlock.call():\n  • args=('<KerasTensor shape=(None, 10, 64), dtype=float32, sparse=False, name=keras_tensor_4>',)\n  • kwargs=<class 'inspect._empty'>",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m y_test_context \u001b[38;5;241m=\u001b[39m to_categorical(y_test[:, \u001b[38;5;241m2\u001b[39m], num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(le_context\u001b[38;5;241m.\u001b[39mclasses_))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Build and train model\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mle_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mle_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mle_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mfit([X_train_event, X_train_agent, X_train_context],\n\u001b[0;32m     23\u001b[0m             [y_train_event, y_train_agent, y_train_context],\n\u001b[0;32m     24\u001b[0m             validation_data\u001b[38;5;241m=\u001b[39m([X_test_event, X_test_agent, X_test_context],\n\u001b[0;32m     25\u001b[0m                             [y_test_event, y_test_agent, y_test_context]),\n\u001b[0;32m     26\u001b[0m             epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[5], line 50\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(input_shape, num_classes, n_layers)\u001b[0m\n\u001b[0;32m     47\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m)(concat)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_layers):\n\u001b[1;32m---> 50\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mSimplifiedMambaBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mLayerNormalization()(x)\n\u001b[0;32m     53\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mGlobalAveragePooling1D()(x)\n",
            "File \u001b[1;32mc:\\Users\\vaibh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "Cell \u001b[1;32mIn[5], line 33\u001b[0m, in \u001b[0;36mSimplifiedMambaBlock.call\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m u \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmatmul(x, tf\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB))\n\u001b[0;32m     32\u001b[0m v \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmatmul(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC, tf\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mexpm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len)))\n\u001b[1;32m---> 33\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m y \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m+\u001b[39m x \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD\n\u001b[0;32m     36\u001b[0m y \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m*\u001b[39m gate\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Exception encountered when calling SimplifiedMambaBlock.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'simplified_mamba_block' (of type SimplifiedMambaBlock). Either the `SimplifiedMambaBlock.call()` method is incorrect, or you need to implement the `SimplifiedMambaBlock.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nDimensions must be equal, but are 16 and 128 for '{{node MatMul_2}} = BatchMatMulV2[T=DT_FLOAT, adj_x=false, adj_y=false, grad_x=false, grad_y=false](MatMul, MatMul_1)' with input shapes: [?,10,16], [128,16].\u001b[0m\n\nArguments received by SimplifiedMambaBlock.call():\n  • args=('<KerasTensor shape=(None, 10, 64), dtype=float32, sparse=False, name=keras_tensor_4>',)\n  • kwargs=<class 'inspect._empty'>"
          ]
        }
      ],
      "source": [
        "# Prepare inputs and outputs\n",
        "X_train_event = X_train[:, :, 0].reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_train_agent = X_train[:, :, 1].reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_train_context = X_train[:, :, 2].reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "\n",
        "X_test_event = X_test[:, :, 0].reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "X_test_agent = X_test[:, :, 1].reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "X_test_context = X_test[:, :, 2].reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "y_train_event = to_categorical(y_train[:, 0], num_classes=len(le_event.classes_))\n",
        "y_train_agent = to_categorical(y_train[:, 1], num_classes=len(le_agent.classes_))\n",
        "y_train_context = to_categorical(y_train[:, 2], num_classes=len(le_context.classes_))\n",
        "\n",
        "y_test_event = to_categorical(y_test[:, 0], num_classes=len(le_event.classes_))\n",
        "y_test_agent = to_categorical(y_test[:, 1], num_classes=len(le_agent.classes_))\n",
        "y_test_context = to_categorical(y_test[:, 2], num_classes=len(le_context.classes_))\n",
        "\n",
        "# Build and train model\n",
        "model = build_model(X_train_event.shape[1:],\n",
        "                    [len(le_event.classes_), len(le_agent.classes_), len(le_context.classes_)])\n",
        "\n",
        "model.fit([X_train_event, X_train_agent, X_train_context],\n",
        "            [y_train_event, y_train_agent, y_train_context],\n",
        "            validation_data=([X_test_event, X_test_agent, X_test_context],\n",
        "                            [y_test_event, y_test_agent, y_test_context]),\n",
        "            epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate model\n",
        "results = model.evaluate(\n",
        "        [X_test_event, X_test_agent, X_test_context],\n",
        "        [y_test_event, y_test_agent, y_test_context]\n",
        "    )\n",
        "    \n",
        "    # Print evaluation results\n",
        "print(\"Test Results:\")\n",
        "for metric_name, value in zip(model.metrics_names, results):\n",
        "        print(f\"{metric_name}: {value:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict next moves for a random sequence from the dataset\n",
        "import random\n",
        "k = 10  # size of initial sequence, changed to 10\n",
        "n_predictions = 15  # number of moves to predict\n",
        "\n",
        "# Select a random sequence from the dataset\n",
        "random_index = random.randint(0, len(X) - 1)\n",
        "initial_sequence = X[random_index]\n",
        "\n",
        "predictions = predict_next_moves(model, initial_sequence, le_event, le_agent, le_context, n_predictions)\n",
        "\n",
        "print(\"Initial sequence:\")\n",
        "for i in range(k):\n",
        "    event = le_event.inverse_transform([initial_sequence[i, 0]])[0]\n",
        "    agent = le_agent.inverse_transform([initial_sequence[i, 1]])[0]\n",
        "    context = le_context.inverse_transform([initial_sequence[i, 2]])[0]\n",
        "    context = '' if context == '<EMPTY>' else context\n",
        "    print(f\"{event}, {agent}, {context}\")\n",
        "\n",
        "print(\"/nPredicted moves:\")\n",
        "for i, (event, agent, context) in enumerate(predictions, 1):\n",
        "    print(f\"Move {i}: {event}, {agent}, {context}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assume `model` is your Keras model\n",
        "model.save('../../results/models/BiDir_LSTM_ATTN.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assume `model` is your Keras model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcK-xKpcLpE3",
        "outputId": "fa0d510c-a30b-4b0f-ee8d-18a3ad21fc21"
      },
      "outputs": [],
      "source": [
        "# # Main pipeline\n",
        "\n",
        "# # Load and preprocess data\n",
        "# df = load_data('../../data/processed/games/tic-tac-toe/50k_single_agent.csv')\n",
        "# df, le_event, le_agent, le_context = preprocess_data(df)\n",
        "\n",
        "# # Create sequences\n",
        "# sequence_length = 10\n",
        "# X, y = create_sequences(df, sequence_length)\n",
        "\n",
        "# # Split data\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Prepare inputs and outputs\n",
        "# X_train_event = X_train[:, :, 0].reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "# X_train_agent = X_train[:, :, 1].reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "# X_train_context = X_train[:, :, 2].reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "\n",
        "# X_test_event = X_test[:, :, 0].reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "# X_test_agent = X_test[:, :, 1].reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "# X_test_context = X_test[:, :, 2].reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# y_train_event = to_categorical(y_train[:, 0], num_classes=len(le_event.classes_))\n",
        "# y_train_agent = to_categorical(y_train[:, 1], num_classes=len(le_agent.classes_))\n",
        "# y_train_context = to_categorical(y_train[:, 2], num_classes=len(le_context.classes_))\n",
        "\n",
        "# y_test_event = to_categorical(y_test[:, 0], num_classes=len(le_event.classes_))\n",
        "# y_test_agent = to_categorical(y_test[:, 1], num_classes=len(le_agent.classes_))\n",
        "# y_test_context = to_categorical(y_test[:, 2], num_classes=len(le_context.classes_))\n",
        "\n",
        "# # Build and train model\n",
        "# model = build_model(X_train_event.shape[1:],\n",
        "#                     [len(le_event.classes_), len(le_agent.classes_), len(le_context.classes_)])\n",
        "\n",
        "# model.fit([X_train_event, X_train_agent, X_train_context],\n",
        "#             [y_train_event, y_train_agent, y_train_context],\n",
        "#             validation_data=([X_test_event, X_test_agent, X_test_context],\n",
        "#                             [y_test_event, y_test_agent, y_test_context]),\n",
        "#             epochs=50, batch_size=32)\n",
        "\n",
        "# # Evaluate model\n",
        "# results = model.evaluate(\n",
        "#         [X_test_event, X_test_agent, X_test_context],\n",
        "#         [y_test_event, y_test_agent, y_test_context]\n",
        "#     )\n",
        "    \n",
        "#     # Print evaluation results\n",
        "# print(\"Test Results:\")\n",
        "# for metric_name, value in zip(model.metrics_names, results):\n",
        "#         print(f\"{metric_name}: {value:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbJZ_39ML1pN",
        "outputId": "51c1ab10-dca6-457d-c3cd-187e207914ee"
      },
      "outputs": [],
      "source": [
        "# custom_log = np.array([\n",
        "#         [le_event.transform(['GAME_START'])[0], le_agent.transform(['system'])[0], le_context.transform(['New Game'])[0]],\n",
        "#         [le_event.transform(['MOVE'])[0], le_agent.transform(['X'])[0], le_context.transform(['2,2'])[0]],\n",
        "#         [le_event.transform(['MOVE'])[0], le_agent.transform(['O'])[0], le_context.transform(['2,0'])[0]]\n",
        "#     ])\n",
        "\n",
        "# # Pad the custom log to match the sequence length of 10\n",
        "\n",
        "\n",
        "# for _ in range(5):\n",
        "#     # Pad the custom log to match the sequence length of 10\n",
        "#     if custom_log.shape[0] < sequence_length:\n",
        "#         padding = np.zeros((sequence_length - custom_log.shape[0], 3), dtype=int)\n",
        "#         custom_log_padded = np.vstack((padding, custom_log))\n",
        "#     else:\n",
        "#         custom_log_padded = custom_log[-sequence_length:]  # Keep only the last sequence_length elements\n",
        "\n",
        "#     custom_event = custom_log_padded[:, 0].reshape(1, sequence_length, 1)\n",
        "#     custom_agent = custom_log_padded[:, 1].reshape(1, sequence_length, 1)\n",
        "#     custom_context = custom_log_padded[:, 2].reshape(1, sequence_length, 1)\n",
        "\n",
        "#     predictions = model.predict([custom_event, custom_agent, custom_context])\n",
        "\n",
        "#     predicted_event = le_event.inverse_transform([np.argmax(predictions[0])])\n",
        "#     predicted_agent = le_agent.inverse_transform([np.argmax(predictions[1])])\n",
        "#     predicted_context = le_context.inverse_transform([np.argmax(predictions[2])])\n",
        "\n",
        "#     print(f\"Predicted next move: {predicted_event[0]}, {predicted_agent[0]}, {predicted_context[0]}\")\n",
        "#     custom_log = np.vstack((custom_log, [le_event.transform([predicted_event[0]])[0], le_agent.transform([predicted_agent[0]])[0], le_context.transform([predicted_context[0]])[0]]))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBEbcRDDNHQl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
