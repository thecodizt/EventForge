{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../../')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SVX9K6RK_jk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Concatenate\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imSt6RsNLF19"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess data\n",
        "def load_data(file_path):\n",
        "    df = pd.read_csv(file_path, header=None, names=['event_type', 'agent_id', 'context'])\n",
        "    return df\n",
        "\n",
        "def preprocess_data(df):\n",
        "    le_event = LabelEncoder()\n",
        "    le_agent = LabelEncoder()\n",
        "    le_context = LabelEncoder()\n",
        "\n",
        "    # Replace empty strings with a special token\n",
        "    df['context'] = df['context'].replace('', '<EMPTY>')\n",
        "\n",
        "    df['event_type_encoded'] = le_event.fit_transform(df['event_type'])\n",
        "    df['agent_id_encoded'] = le_agent.fit_transform(df['agent_id'])\n",
        "    df['context_encoded'] = le_context.fit_transform(df['context'])\n",
        "\n",
        "    return df, le_event, le_agent, le_context\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ms5K8836LZ9F"
      },
      "outputs": [],
      "source": [
        "# Create sequences\n",
        "def create_sequences(df, sequence_length):\n",
        "    sequences = []\n",
        "    targets = []\n",
        "\n",
        "    for i in range(len(df) - sequence_length):\n",
        "        seq = df.iloc[i:i+sequence_length]\n",
        "        target = df.iloc[i+sequence_length]\n",
        "\n",
        "        sequences.append(seq[['event_type_encoded', 'agent_id_encoded', 'context_encoded']].values)\n",
        "        targets.append([target['event_type_encoded'], target['agent_id_encoded'], target['context_encoded']])\n",
        "\n",
        "    return np.array(sequences), np.array(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1a9OKyrLmoi"
      },
      "outputs": [],
      "source": [
        "# Build model\n",
        "def build_model(input_shape, num_classes):\n",
        "    input_event = Input(shape=(input_shape[0], 1))\n",
        "    input_agent = Input(shape=(input_shape[0], 1))\n",
        "    input_context = Input(shape=(input_shape[0], 1))\n",
        "\n",
        "    concat = Concatenate()([input_event, input_agent, input_context])\n",
        "\n",
        "    lstm = LSTM(64, return_sequences=False)(concat)\n",
        "\n",
        "    output_event = Dense(num_classes[0], activation='softmax', name='event_type')(lstm)\n",
        "    output_agent = Dense(num_classes[1], activation='softmax', name='agent_id')(lstm)\n",
        "    output_context = Dense(num_classes[2], activation='softmax', name='context')(lstm)\n",
        "\n",
        "    model = Model(inputs=[input_event, input_agent, input_context],\n",
        "                  outputs=[output_event, output_agent, output_context])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy','accuracy','accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_next_moves(model, initial_sequence, le_event, le_agent, le_context, n_predictions):\n",
        "    predictions = []\n",
        "    current_sequence = initial_sequence.copy()\n",
        "\n",
        "    for _ in range(n_predictions):\n",
        "        custom_event = current_sequence[:, 0].reshape(1, -1, 1)\n",
        "        custom_agent = current_sequence[:, 1].reshape(1, -1, 1)\n",
        "        custom_context = current_sequence[:, 2].reshape(1, -1, 1)\n",
        "\n",
        "        prediction = model.predict([custom_event, custom_agent, custom_context])\n",
        "\n",
        "        predicted_event = le_event.inverse_transform([np.argmax(prediction[0])])[0]\n",
        "        predicted_agent = le_agent.inverse_transform([np.argmax(prediction[1])])[0]\n",
        "        predicted_context = le_context.inverse_transform([np.argmax(prediction[2])])[0]\n",
        "\n",
        "        predicted_context = '' if predicted_context == '<EMPTY>' else predicted_context\n",
        "\n",
        "        predictions.append((predicted_event, predicted_agent, predicted_context))\n",
        "\n",
        "        # Update the sequence for the next prediction\n",
        "        new_row = np.array([[\n",
        "            le_event.transform([predicted_event])[0],\n",
        "            le_agent.transform([predicted_agent])[0],\n",
        "            le_context.transform([predicted_context if predicted_context != '' else '<EMPTY>'])[0]\n",
        "        ]])\n",
        "        current_sequence = np.vstack((current_sequence[1:], new_row))\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and preprocess data\n",
        "df = load_data('..\\..\\data\\processed/games/tic-tac-toe/50k_single_agent.csv')\n",
        "df, le_event, le_agent, le_context = preprocess_data(df)\n",
        "\n",
        "# Create sequences\n",
        "sequence_length = 10  # Changed to 10\n",
        "X, y = create_sequences(df, sequence_length)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m12025/12025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 6ms/step - agent_id_accuracy: 0.8922 - context_accuracy: 0.2627 - event_type_accuracy: 0.9231 - loss: 2.3702 - val_agent_id_accuracy: 0.9331 - val_context_accuracy: 0.2881 - val_event_type_accuracy: 0.9331 - val_loss: 2.1171\n",
            "Epoch 2/10\n",
            "\u001b[1m12025/12025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 6ms/step - agent_id_accuracy: 0.9325 - context_accuracy: 0.2922 - event_type_accuracy: 0.9328 - loss: 2.0959 - val_agent_id_accuracy: 0.9356 - val_context_accuracy: 0.3051 - val_event_type_accuracy: 0.9354 - val_loss: 2.0255\n",
            "Epoch 3/10\n",
            "\u001b[1m12025/12025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - agent_id_accuracy: 0.9373 - context_accuracy: 0.3109 - event_type_accuracy: 0.9378 - loss: 1.9902 - val_agent_id_accuracy: 0.9434 - val_context_accuracy: 0.3250 - val_event_type_accuracy: 0.9437 - val_loss: 1.8965\n",
            "Epoch 4/10\n",
            "\u001b[1m12025/12025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 5ms/step - agent_id_accuracy: 0.9431 - context_accuracy: 0.3264 - event_type_accuracy: 0.9431 - loss: 1.8749 - val_agent_id_accuracy: 0.9488 - val_context_accuracy: 0.3383 - val_event_type_accuracy: 0.9485 - val_loss: 1.8259\n",
            "Epoch 5/10\n",
            "\u001b[1m12025/12025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - agent_id_accuracy: 0.9493 - context_accuracy: 0.3374 - event_type_accuracy: 0.9493 - loss: 1.8169 - val_agent_id_accuracy: 0.9525 - val_context_accuracy: 0.3426 - val_event_type_accuracy: 0.9523 - val_loss: 1.7792\n",
            "Epoch 6/10\n",
            "\u001b[1m12025/12025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - agent_id_accuracy: 0.9537 - context_accuracy: 0.3436 - event_type_accuracy: 0.9538 - loss: 1.7666 - val_agent_id_accuracy: 0.9577 - val_context_accuracy: 0.3485 - val_event_type_accuracy: 0.9576 - val_loss: 1.7130\n",
            "Epoch 7/10\n",
            "\u001b[1m12025/12025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - agent_id_accuracy: 0.9567 - context_accuracy: 0.3516 - event_type_accuracy: 0.9569 - loss: 1.7047 - val_agent_id_accuracy: 0.9573 - val_context_accuracy: 0.3561 - val_event_type_accuracy: 0.9583 - val_loss: 1.6636\n",
            "Epoch 8/10\n",
            "\u001b[1m12025/12025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - agent_id_accuracy: 0.9587 - context_accuracy: 0.3555 - event_type_accuracy: 0.9591 - loss: 1.6627 - val_agent_id_accuracy: 0.9612 - val_context_accuracy: 0.3611 - val_event_type_accuracy: 0.9615 - val_loss: 1.6353\n",
            "Epoch 9/10\n",
            "\u001b[1m12025/12025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 4ms/step - agent_id_accuracy: 0.9616 - context_accuracy: 0.3607 - event_type_accuracy: 0.9619 - loss: 1.6268 - val_agent_id_accuracy: 0.9656 - val_context_accuracy: 0.3641 - val_event_type_accuracy: 0.9654 - val_loss: 1.6020\n",
            "Epoch 10/10\n",
            "\u001b[1m12025/12025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3ms/step - agent_id_accuracy: 0.9648 - context_accuracy: 0.3651 - event_type_accuracy: 0.9653 - loss: 1.5958 - val_agent_id_accuracy: 0.9662 - val_context_accuracy: 0.3648 - val_event_type_accuracy: 0.9661 - val_loss: 1.5794\n",
            "\u001b[1m3007/3007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - agent_id_accuracy: 0.9659 - context_accuracy: 0.3612 - event_type_accuracy: 0.9656 - loss: 1.5833\n",
            "Test Results:\n",
            "loss: 1.5794\n",
            "compile_metrics: 0.9662\n"
          ]
        }
      ],
      "source": [
        "# Main pipeline\n",
        "\n",
        "# Load and preprocess data\n",
        "df = load_data('..\\..\\data\\processed/games/tic-tac-toe/50k_single_agent.csv')\n",
        "df, le_event, le_agent, le_context = preprocess_data(df)\n",
        "\n",
        "# Create sequences\n",
        "sequence_length = 10\n",
        "X, y = create_sequences(df, sequence_length)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Prepare inputs and outputs\n",
        "X_train_event = X_train[:, :, 0].reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_train_agent = X_train[:, :, 1].reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_train_context = X_train[:, :, 2].reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "\n",
        "X_test_event = X_test[:, :, 0].reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "X_test_agent = X_test[:, :, 1].reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "X_test_context = X_test[:, :, 2].reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "y_train_event = to_categorical(y_train[:, 0], num_classes=len(le_event.classes_))\n",
        "y_train_agent = to_categorical(y_train[:, 1], num_classes=len(le_agent.classes_))\n",
        "y_train_context = to_categorical(y_train[:, 2], num_classes=len(le_context.classes_))\n",
        "\n",
        "y_test_event = to_categorical(y_test[:, 0], num_classes=len(le_event.classes_))\n",
        "y_test_agent = to_categorical(y_test[:, 1], num_classes=len(le_agent.classes_))\n",
        "y_test_context = to_categorical(y_test[:, 2], num_classes=len(le_context.classes_))\n",
        "\n",
        "# Build and train model\n",
        "model = build_model(X_train_event.shape[1:],\n",
        "                    [len(le_event.classes_), len(le_agent.classes_), len(le_context.classes_)])\n",
        "\n",
        "model.fit([X_train_event, X_train_agent, X_train_context],\n",
        "            [y_train_event, y_train_agent, y_train_context],\n",
        "            validation_data=([X_test_event, X_test_agent, X_test_context],\n",
        "                            [y_test_event, y_test_agent, y_test_context]),\n",
        "            epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate model\n",
        "results = model.evaluate(\n",
        "        [X_test_event, X_test_agent, X_test_context],\n",
        "        [y_test_event, y_test_agent, y_test_context]\n",
        "    )\n",
        "    \n",
        "    # Print evaluation results\n",
        "print(\"Test Results:\")\n",
        "for metric_name, value in zip(model.metrics_names, results):\n",
        "        print(f\"{metric_name}: {value:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Initial sequence:\n",
            "MOVE, O, 2,2\n",
            "MOVE, X, 0,2\n",
            "MOVE, O, 2,0\n",
            "MOVE, X, 1,1\n",
            "MOVE, O, 2,1\n",
            "GAME_END, system, O\n",
            "GAME_START, system, New Game\n",
            "MOVE, X, 2,0\n",
            "MOVE, O, 2,2\n",
            "MOVE, X, 0,2\n",
            "\n",
            "Predicted moves:\n",
            "Move 1: MOVE, O, 1,1\n",
            "Move 2: MOVE, X, 0,0\n",
            "Move 3: MOVE, O, 1,0\n",
            "Move 4: MOVE, X, 0,1\n",
            "Move 5: GAME_END, system, X\n",
            "Move 6: GAME_START, system, New Game\n",
            "Move 7: MOVE, X, 1,1\n",
            "Move 8: MOVE, O, 2,0\n",
            "Move 9: MOVE, X, 2,2\n",
            "Move 10: MOVE, O, 0,2\n",
            "Move 11: MOVE, X, 0,0\n",
            "Move 12: GAME_END, system, X\n",
            "Move 13: GAME_START, system, New Game\n",
            "Move 14: MOVE, X, 2,1\n",
            "Move 15: MOVE, O, 1,2\n"
          ]
        }
      ],
      "source": [
        "# Predict next moves for a random sequence from the dataset\n",
        "import random\n",
        "k = 10  # size of initial sequence, changed to 10\n",
        "n_predictions = 15  # number of moves to predict\n",
        "\n",
        "# Select a random sequence from the dataset\n",
        "random_index = random.randint(0, len(X) - 1)\n",
        "initial_sequence = X[random_index]\n",
        "\n",
        "predictions = predict_next_moves(model, initial_sequence, le_event, le_agent, le_context, n_predictions)\n",
        "\n",
        "print(\"Initial sequence:\")\n",
        "for i in range(k):\n",
        "    event = le_event.inverse_transform([initial_sequence[i, 0]])[0]\n",
        "    agent = le_agent.inverse_transform([initial_sequence[i, 1]])[0]\n",
        "    context = le_context.inverse_transform([initial_sequence[i, 2]])[0]\n",
        "    context = '' if context == '<EMPTY>' else context\n",
        "    print(f\"{event}, {agent}, {context}\")\n",
        "\n",
        "print(\"\\nPredicted moves:\")\n",
        "for i, (event, agent, context) in enumerate(predictions, 1):\n",
        "    print(f\"Move {i}: {event}, {agent}, {context}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcK-xKpcLpE3",
        "outputId": "fa0d510c-a30b-4b0f-ee8d-18a3ad21fc21"
      },
      "outputs": [],
      "source": [
        "# # Main pipeline\n",
        "\n",
        "# # Load and preprocess data\n",
        "# df = load_data('..\\..\\data\\processed/games/tic-tac-toe/50k_single_agent.csv')\n",
        "# df, le_event, le_agent, le_context = preprocess_data(df)\n",
        "\n",
        "# # Create sequences\n",
        "# sequence_length = 10\n",
        "# X, y = create_sequences(df, sequence_length)\n",
        "\n",
        "# # Split data\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Prepare inputs and outputs\n",
        "# X_train_event = X_train[:, :, 0].reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "# X_train_agent = X_train[:, :, 1].reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "# X_train_context = X_train[:, :, 2].reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "\n",
        "# X_test_event = X_test[:, :, 0].reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "# X_test_agent = X_test[:, :, 1].reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "# X_test_context = X_test[:, :, 2].reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# y_train_event = to_categorical(y_train[:, 0], num_classes=len(le_event.classes_))\n",
        "# y_train_agent = to_categorical(y_train[:, 1], num_classes=len(le_agent.classes_))\n",
        "# y_train_context = to_categorical(y_train[:, 2], num_classes=len(le_context.classes_))\n",
        "\n",
        "# y_test_event = to_categorical(y_test[:, 0], num_classes=len(le_event.classes_))\n",
        "# y_test_agent = to_categorical(y_test[:, 1], num_classes=len(le_agent.classes_))\n",
        "# y_test_context = to_categorical(y_test[:, 2], num_classes=len(le_context.classes_))\n",
        "\n",
        "# # Build and train model\n",
        "# model = build_model(X_train_event.shape[1:],\n",
        "#                     [len(le_event.classes_), len(le_agent.classes_), len(le_context.classes_)])\n",
        "\n",
        "# model.fit([X_train_event, X_train_agent, X_train_context],\n",
        "#             [y_train_event, y_train_agent, y_train_context],\n",
        "#             validation_data=([X_test_event, X_test_agent, X_test_context],\n",
        "#                             [y_test_event, y_test_agent, y_test_context]),\n",
        "#             epochs=50, batch_size=32)\n",
        "\n",
        "# # Evaluate model\n",
        "# results = model.evaluate(\n",
        "#         [X_test_event, X_test_agent, X_test_context],\n",
        "#         [y_test_event, y_test_agent, y_test_context]\n",
        "#     )\n",
        "    \n",
        "#     # Print evaluation results\n",
        "# print(\"Test Results:\")\n",
        "# for metric_name, value in zip(model.metrics_names, results):\n",
        "#         print(f\"{metric_name}: {value:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbJZ_39ML1pN",
        "outputId": "51c1ab10-dca6-457d-c3cd-187e207914ee"
      },
      "outputs": [],
      "source": [
        "# custom_log = np.array([\n",
        "#         [le_event.transform(['GAME_START'])[0], le_agent.transform(['system'])[0], le_context.transform(['New Game'])[0]],\n",
        "#         [le_event.transform(['MOVE'])[0], le_agent.transform(['X'])[0], le_context.transform(['2,2'])[0]],\n",
        "#         [le_event.transform(['MOVE'])[0], le_agent.transform(['O'])[0], le_context.transform(['2,0'])[0]]\n",
        "#     ])\n",
        "\n",
        "# # Pad the custom log to match the sequence length of 10\n",
        "\n",
        "\n",
        "# for _ in range(5):\n",
        "#     # Pad the custom log to match the sequence length of 10\n",
        "#     if custom_log.shape[0] < sequence_length:\n",
        "#         padding = np.zeros((sequence_length - custom_log.shape[0], 3), dtype=int)\n",
        "#         custom_log_padded = np.vstack((padding, custom_log))\n",
        "#     else:\n",
        "#         custom_log_padded = custom_log[-sequence_length:]  # Keep only the last sequence_length elements\n",
        "\n",
        "#     custom_event = custom_log_padded[:, 0].reshape(1, sequence_length, 1)\n",
        "#     custom_agent = custom_log_padded[:, 1].reshape(1, sequence_length, 1)\n",
        "#     custom_context = custom_log_padded[:, 2].reshape(1, sequence_length, 1)\n",
        "\n",
        "#     predictions = model.predict([custom_event, custom_agent, custom_context])\n",
        "\n",
        "#     predicted_event = le_event.inverse_transform([np.argmax(predictions[0])])\n",
        "#     predicted_agent = le_agent.inverse_transform([np.argmax(predictions[1])])\n",
        "#     predicted_context = le_context.inverse_transform([np.argmax(predictions[2])])\n",
        "\n",
        "#     print(f\"Predicted next move: {predicted_event[0]}, {predicted_agent[0]}, {predicted_context[0]}\")\n",
        "#     custom_log = np.vstack((custom_log, [le_event.transform([predicted_event[0]])[0], le_agent.transform([predicted_agent[0]])[0], le_context.transform([predicted_context[0]])[0]]))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBEbcRDDNHQl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
