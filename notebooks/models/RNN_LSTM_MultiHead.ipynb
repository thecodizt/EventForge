{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../../')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-SVX9K6RK_jk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Concatenate\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "imSt6RsNLF19"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess data\n",
        "def load_data(file_path):\n",
        "    df = pd.read_csv(file_path, header=None, names=['event_type', 'agent_id', 'context'])\n",
        "    return df\n",
        "\n",
        "def preprocess_data(df):\n",
        "    le_event = LabelEncoder()\n",
        "    le_agent = LabelEncoder()\n",
        "    le_context = LabelEncoder()\n",
        "\n",
        "    # Replace empty strings with a special token\n",
        "    df['context'] = df['context'].replace('', '<EMPTY>')\n",
        "\n",
        "    df['event_type_encoded'] = le_event.fit_transform(df['event_type'])\n",
        "    df['agent_id_encoded'] = le_agent.fit_transform(df['agent_id'])\n",
        "    df['context_encoded'] = le_context.fit_transform(df['context'])\n",
        "\n",
        "    return df, le_event, le_agent, le_context\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ms5K8836LZ9F"
      },
      "outputs": [],
      "source": [
        "# Create sequences\n",
        "def create_sequences(df, sequence_length):\n",
        "    sequences = []\n",
        "    targets = []\n",
        "\n",
        "    for i in range(len(df) - sequence_length):\n",
        "        seq = df.iloc[i:i+sequence_length]\n",
        "        target = df.iloc[i+sequence_length]\n",
        "\n",
        "        sequences.append(seq[['event_type_encoded', 'agent_id_encoded', 'context_encoded']].values)\n",
        "        targets.append([target['event_type_encoded'], target['agent_id_encoded'], target['context_encoded']])\n",
        "\n",
        "    return np.array(sequences), np.array(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "o1a9OKyrLmoi"
      },
      "outputs": [],
      "source": [
        "# Build model\n",
        "def build_model(input_shape, num_classes):\n",
        "    input_event = Input(shape=(input_shape[0], 1))\n",
        "    input_agent = Input(shape=(input_shape[0], 1))\n",
        "    input_context = Input(shape=(input_shape[0], 1))\n",
        "\n",
        "    concat = Concatenate()([input_event, input_agent, input_context])\n",
        "\n",
        "    lstm = LSTM(64, return_sequences=False)(concat)\n",
        "\n",
        "    output_event = Dense(num_classes[0], activation='softmax', name='event_type')(lstm)\n",
        "    output_agent = Dense(num_classes[1], activation='softmax', name='agent_id')(lstm)\n",
        "    output_context = Dense(num_classes[2], activation='softmax', name='context')(lstm)\n",
        "\n",
        "    model = Model(inputs=[input_event, input_agent, input_context],\n",
        "                  outputs=[output_event, output_agent, output_context])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy','accuracy','accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcK-xKpcLpE3",
        "outputId": "fa0d510c-a30b-4b0f-ee8d-18a3ad21fc21"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[19], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Create sequences\u001b[39;00m\n\u001b[0;32m      8\u001b[0m sequence_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m----> 9\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Split data\u001b[39;00m\n\u001b[0;32m     12\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
            "Cell \u001b[1;32mIn[4], line 10\u001b[0m, in \u001b[0;36mcreate_sequences\u001b[1;34m(df, sequence_length)\u001b[0m\n\u001b[0;32m      7\u001b[0m     seq \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[i:i\u001b[38;5;241m+\u001b[39msequence_length]\n\u001b[0;32m      8\u001b[0m     target \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[i\u001b[38;5;241m+\u001b[39msequence_length]\n\u001b[1;32m---> 10\u001b[0m     sequences\u001b[38;5;241m.\u001b[39mappend(\u001b[43mseq\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mevent_type_encoded\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43magent_id_encoded\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontext_encoded\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m)\n\u001b[0;32m     11\u001b[0m     targets\u001b[38;5;241m.\u001b[39mappend([target[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_type_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m], target[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124magent_id_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m], target[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(sequences), np\u001b[38;5;241m.\u001b[39marray(targets)\n",
            "File \u001b[1;32mc:\\Users\\vaibh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:12284\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  12210\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m  12211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m  12212\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m  12213\u001b[0m \u001b[38;5;124;03m    Return a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[0;32m  12214\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12282\u001b[0m \u001b[38;5;124;03m           ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[0;32m  12283\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m> 12284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\vaibh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1656\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1654\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1656\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1657\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
            "File \u001b[1;32mc:\\Users\\vaibh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1716\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1714\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[0;32m   1715\u001b[0m     result[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m-> 1716\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m   1719\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome items were not contained in blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Main pipeline\n",
        "\n",
        "# Load and preprocess data\n",
        "df = load_data('..\\..\\data\\processed/games/tic-tac-toe/50k_single_agent.csv')\n",
        "df, le_event, le_agent, le_context = preprocess_data(df)\n",
        "\n",
        "# Create sequences\n",
        "sequence_length = 10\n",
        "X, y = create_sequences(df, sequence_length)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Prepare inputs and outputs\n",
        "X_train_event = X_train[:, :, 0].reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_train_agent = X_train[:, :, 1].reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_train_context = X_train[:, :, 2].reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "\n",
        "X_test_event = X_test[:, :, 0].reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "X_test_agent = X_test[:, :, 1].reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "X_test_context = X_test[:, :, 2].reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "y_train_event = to_categorical(y_train[:, 0], num_classes=len(le_event.classes_))\n",
        "y_train_agent = to_categorical(y_train[:, 1], num_classes=len(le_agent.classes_))\n",
        "y_train_context = to_categorical(y_train[:, 2], num_classes=len(le_context.classes_))\n",
        "\n",
        "y_test_event = to_categorical(y_test[:, 0], num_classes=len(le_event.classes_))\n",
        "y_test_agent = to_categorical(y_test[:, 1], num_classes=len(le_agent.classes_))\n",
        "y_test_context = to_categorical(y_test[:, 2], num_classes=len(le_context.classes_))\n",
        "\n",
        "# Build and train model\n",
        "model = build_model(X_train_event.shape[1:],\n",
        "                    [len(le_event.classes_), len(le_agent.classes_), len(le_context.classes_)])\n",
        "\n",
        "model.fit([X_train_event, X_train_agent, X_train_context],\n",
        "            [y_train_event, y_train_agent, y_train_context],\n",
        "            validation_data=([X_test_event, X_test_agent, X_test_context],\n",
        "                            [y_test_event, y_test_agent, y_test_context]),\n",
        "            epochs=50, batch_size=32)\n",
        "\n",
        "# Evaluate model\n",
        "results = model.evaluate(\n",
        "        [X_test_event, X_test_agent, X_test_context],\n",
        "        [y_test_event, y_test_agent, y_test_context]\n",
        "    )\n",
        "    \n",
        "    # Print evaluation results\n",
        "print(\"Test Results:\")\n",
        "for metric_name, value in zip(model.metrics_names, results):\n",
        "        print(f\"{metric_name}: {value:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbJZ_39ML1pN",
        "outputId": "51c1ab10-dca6-457d-c3cd-187e207914ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Predicted next move: MOVE, X, 0,0\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Predicted next move: MOVE, O, 2,1\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Predicted next move: MOVE, X, 1,0\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Predicted next move: MOVE, O, 2,1\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "Predicted next move: MOVE, X, 2,1\n"
          ]
        }
      ],
      "source": [
        "custom_log = np.array([\n",
        "        [le_event.transform(['GAME_START'])[0], le_agent.transform(['system'])[0], le_context.transform(['New Game'])[0]],\n",
        "        [le_event.transform(['MOVE'])[0], le_agent.transform(['X'])[0], le_context.transform(['2,2'])[0]],\n",
        "        [le_event.transform(['MOVE'])[0], le_agent.transform(['O'])[0], le_context.transform(['2,0'])[0]]\n",
        "    ])\n",
        "\n",
        "# Pad the custom log to match the sequence length of 10\n",
        "\n",
        "\n",
        "for _ in range(5):\n",
        "    # Pad the custom log to match the sequence length of 10\n",
        "    if custom_log.shape[0] < sequence_length:\n",
        "        padding = np.zeros((sequence_length - custom_log.shape[0], 3), dtype=int)\n",
        "        custom_log_padded = np.vstack((padding, custom_log))\n",
        "    else:\n",
        "        custom_log_padded = custom_log[-sequence_length:]  # Keep only the last sequence_length elements\n",
        "\n",
        "    custom_event = custom_log_padded[:, 0].reshape(1, sequence_length, 1)\n",
        "    custom_agent = custom_log_padded[:, 1].reshape(1, sequence_length, 1)\n",
        "    custom_context = custom_log_padded[:, 2].reshape(1, sequence_length, 1)\n",
        "\n",
        "    predictions = model.predict([custom_event, custom_agent, custom_context])\n",
        "\n",
        "    predicted_event = le_event.inverse_transform([np.argmax(predictions[0])])\n",
        "    predicted_agent = le_agent.inverse_transform([np.argmax(predictions[1])])\n",
        "    predicted_context = le_context.inverse_transform([np.argmax(predictions[2])])\n",
        "\n",
        "    print(f\"Predicted next move: {predicted_event[0]}, {predicted_agent[0]}, {predicted_context[0]}\")\n",
        "    custom_log = np.vstack((custom_log, [le_event.transform([predicted_event[0]])[0], le_agent.transform([predicted_agent[0]])[0], le_context.transform([predicted_context[0]])[0]]))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBEbcRDDNHQl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
